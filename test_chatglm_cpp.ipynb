{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatMessage(role=\"assistant\", content=\"你好👋！我是人工智能助手 ChatGLM3-6B，很高兴见到你，欢迎问我任何问题。\", tool_calls=[])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import chatglm_cpp\n",
    "\n",
    "pipeline = chatglm_cpp.Pipeline(\"/home/likegiver/Desktop/codes/huggingface_models/ChatGLM3-6b-int4/chatglm3-ggml-q4_0.bin\")\n",
    "pipeline.chat([chatglm_cpp.ChatMessage(role=\"user\", content=\"你好\")])\n",
    "# Output: 你好👋！我是人工智能助手 ChatGLM3-6B，很高兴见到你，欢迎问我任何问题。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_text = ''\n",
    "for response in pipeline.generate(\n",
    "    prompt = \"你好\",\n",
    "    # tools=None, \n",
    "    stream=True,\n",
    "    do_sample=True,\n",
    "    # max_length=MAX_LENGTH,\n",
    "    # temperature=temperature,\n",
    "    # top_p=top_p,\n",
    "    # stop_sequences=[str(Role.USER)],\n",
    "):\n",
    "    token = response\n",
    "    # if response.token.special:\n",
    "    #     print(\"=== Output:\")\n",
    "    #     print(output_text)\n",
    "\n",
    "        # match token.text.strip():\n",
    "        #     case '<|user|>':\n",
    "        #         break\n",
    "        #     case _:\n",
    "        #         st.error(f'Unexpected special token: {token.text.strip()}')\n",
    "        #         break\n",
    "    output_text += response\n",
    "    # markdown_placeholder.markdown(postprocess_text(output_text + '▌'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'，请问有什么可以帮您的？\\n您好！作为人工智能助手，我很乐意为您提供帮助。请问有什么问题我可以帮您解答或者需要我为您提供哪些服务呢？'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_qimo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
